{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c15938-140a-45db-9bd2-473bf9b7e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee686f7e-2cf1-403d-ac47-ac57da892327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Any, Callable, List, Optional, Tuple\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\") # So we can use the coordination package\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from coordination.model.conversation_model import ConversationModel, ConversationSeries, ConversationSamples\n",
    "from coordination.model.spring_model import SpringModel\n",
    "from coordination.model.coordination_model import CoordinationPosteriorSamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad1a8f6-64f0-48e3-800d-2529f82561de",
   "metadata": {},
   "source": [
    "# Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d52f1-fe5c-4b7c-9c31-3b3ce91add8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "tex_fonts = {\n",
    "    \"axes.labelsize\": 8,\n",
    "    \"font.size\": 8,\n",
    "    \"legend.fontsize\": 8,\n",
    "    \"xtick.labelsize\": 6,\n",
    "    \"ytick.labelsize\": 6,\n",
    "    \"axes.titlesize\": 8,\n",
    "    \"axes.linewidth\": 1\n",
    "}\n",
    "plt.rcParams.update(tex_fonts)\n",
    "plt.rc('pdf',fonttype = 42)\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "DOC_WIDTH = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdecf72-2655-4371-859a-77ce688eafce",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b8867-b442-45dd-ba42-27eeea0483d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_best_figure_dimensions(document_width: Union[str, float], scale=1, subplots=(1, 1)):\n",
    "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
    "    From: https://jwalton.info/Embed-Publication-Matplotlib-Latex/\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    document_width: Union[str, float]\n",
    "            Document textwidth or columnwidth in pts. Predefined strings are also acceptable.\n",
    "    scale: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "    subplots: array-like, optional\n",
    "            The number of rows and columns of subplots.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    width_pt = document_width\n",
    "\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width_pt * scale\n",
    "\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    # https://disq.us/p/2940ij3\n",
    "    golden_ratio = (5 ** .5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "\n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * golden_ratio * (subplots[0] / subplots[1])\n",
    "\n",
    "    return fig_width_in, fig_height_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2ba6e4-779e-4647-865b-2adac64ae9e8",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a70279-8049-49c4-bc64-760b0087dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "COLORS_SPR = [\"#137513\", \"#FF9090\", \"#13B2FF\"]\n",
    "COLORS_CONV = [\"#13B2FF\", \"#FF9090\", \"#137513\"]\n",
    "MUSTARD = \"#BE9700\"\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 0\n",
    "\n",
    "# Data \n",
    "T=100\n",
    "\n",
    "# Spring model\n",
    "NUM_SPRINGS=3\n",
    "SPRING_CONSTANT=np.array([16, 8, 4])\n",
    "MASS=np.ones(NUM_SPRINGS) * 10\n",
    "DAMPING_COEF_SPR=np.zeros(NUM_SPRINGS)\n",
    "DT_SPR=1 # time step size\n",
    "INITIAL_STATE_SPR=np.array([[1, 0], [3, 0], [5, 0]])\n",
    "SD_AA_SPR=0.1  # noise in the model evolution\n",
    "SD_O_SPR=0.1   # noise in the measurement\n",
    "\n",
    "# Conversation model \n",
    "NUM_SUBJECTS=3\n",
    "SUBJECT_NAMES=[\"Bob\", \"Alice\", \"Dan\"]\n",
    "FREQ=np.array([1, 0.5, 0.1])\n",
    "DAMPING_COEF_CONV=np.zeros(NUM_SUBJECTS)\n",
    "DT_CONV=0.2 # time step size\n",
    "INITIAL_STATE_CONV=np.array([[1, 0], [1, 0], [1, 0]])\n",
    "SD_AA_CONV=0.1  # noise in the model evolution\n",
    "SD_O_CONV=0.01  # noise in the measurement\n",
    "\n",
    "# Inference\n",
    "BURN_IN = 2000\n",
    "NUM_SAMPLES = 2000\n",
    "NUM_CHAINS = 4\n",
    "NUTS_INIT_METHOD = \"jitter+adapt_diag\"\n",
    "TARGET_ACCEPT = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08290a49-caa1-4acc-a1c5-14bbbe4acc0b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a3a67-b1a1-4007-9204-f0e9376939c1",
   "metadata": {},
   "source": [
    "## a) Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d3011-c916-4bcb-ac16-1566b9d5e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_model = SpringModel(num_springs=NUM_SPRINGS,\n",
    "                           spring_constant=SPRING_CONSTANT,\n",
    "                           mass=MASS,\n",
    "                           damping_coefficient=DAMPING_COEF_SPR,\n",
    "                           dt=DT_SPR,\n",
    "                           self_dependent=True,\n",
    "                           sd_mean_uc0=1,\n",
    "                           sd_sd_uc=1,\n",
    "                           mean_mean_a0=np.zeros((NUM_SPRINGS, 2)),\n",
    "                           sd_mean_a0=np.ones((NUM_SPRINGS, 2)) * max(INITIAL_STATE_SPR[:, 0]),  # Maximum value among initial positions not to make hyperprior too tight\n",
    "                           sd_sd_aa=np.ones(1),\n",
    "                           sd_sd_o=np.ones(1),\n",
    "                           share_sd_aa_across_springs=True,\n",
    "                           share_sd_aa_across_features=True,  # same variance for position and speed\n",
    "                           share_sd_o_across_springs=True,    # same measurement noise for different springs\n",
    "                           share_sd_o_across_features=True)   # same measurement noise for position and speed                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a3b4dc-7487-488a-833c-6e4454fdb7ca",
   "metadata": {},
   "source": [
    "## b) Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4132fbfc-07d5-4ed7-a742-55543fde03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_model = ConversationModel(num_subjects=NUM_SUBJECTS,\n",
    "                                       frequency=FREQ,\n",
    "                                       damping_coefficient=DAMPING_COEF_CONV,\n",
    "                                       dt=DT_CONV,\n",
    "                                       self_dependent=True,\n",
    "                                       sd_mean_uc0=1,\n",
    "                                       sd_sd_uc=1,\n",
    "                                       mean_mean_a0=np.zeros((NUM_SUBJECTS, 2)),\n",
    "                                       sd_mean_a0=np.ones((NUM_SUBJECTS, 2)) * max(INITIAL_STATE_CONV[:, 0]),\n",
    "                                       sd_sd_aa=np.ones(1),\n",
    "                                       sd_sd_o=np.ones(1),\n",
    "                                       share_sd_aa_across_subjects=True,\n",
    "                                       share_sd_aa_across_features=True,\n",
    "                                       share_sd_o_across_subjects=True,\n",
    "                                       share_sd_o_across_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc173cb6-6921-4b7f-89b0-1c99c752b2a4",
   "metadata": {},
   "source": [
    "# Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b55e0c-5b05-4375-8f40-01ba8aceec1f",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f142a-e8c7-427f-b758-f68a1c731c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spring_data(ax: Any, data: np.ndarray, title: str = \"\", line_width: float = 1, y_shift_fn: Callable = lambda x,s: x):\n",
    "    num_time_steps = data.shape[-1]\n",
    "    \n",
    "    tt = np.arange(num_time_steps)\n",
    "    \n",
    "    for s in range(NUM_SPRINGS):        \n",
    "        ax.plot(tt, y_shift_fn(data[s, 0],s), label=f\"Spring {s + 1}\", color=COLORS_SPR[s], linewidth=line_width, linestyle='solid')\n",
    "        \n",
    "    sns.despine(ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time Step\")\n",
    "    ax.set_ylabel(\"Position\")\n",
    "    \n",
    "def plot_conversation_data(ax: Any, data: conversationSeries, title: str = \"\", line_width: float = 1, y_shift_fn: Callable = lambda x,s: x):\n",
    "    for s, name in enumerate(SUBJECT_NAMES):\n",
    "        tt = np.array([t for t, subject in enumerate(data.subjects_in_time) if s == subject])\n",
    "        ax.plot(tt, y_shift_fn(data.observation[0, tt],s), label=name, color=COLORS_CONV[s], linewidth=line_width, linestyle='solid')\n",
    "    sns.despine(ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time Step\")\n",
    "    ax.set_ylabel(\"Position\")\n",
    "    \n",
    "def conversation_samples_to_evidence(samples: SerialconversationSamples) -> SerialconversationSeries:\n",
    "    return ConversationSeries(subjects_in_time=samples.state.subjects[0],\n",
    "                              prev_time_same_subject=samples.state.prev_time_same_subject[0],\n",
    "                              prev_time_diff_subject=samples.state.prev_time_diff_subject[0],\n",
    "                              observation=samples.observation.values[0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb6d778-cf78-4cab-846a-b7103575ce08",
   "metadata": {},
   "source": [
    "## a) Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a57890-8464-473f-852d-cb0cb9d92b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for data generation\n",
    "spring_model.state_space_cpn.parameters.mean_a0.value=INITIAL_STATE_SPR\n",
    "spring_model.state_space_cpn.parameters.sd_aa.value=np.zeros(1)  # only for plots\n",
    "spring_model.observation_cpn.parameters.sd_o.value=np.zeros(1)\n",
    "\n",
    "# Denoised version is only used for plots\n",
    "T_plot = 50\n",
    "coordination = np.zeros((1, T_plot))\n",
    "spring_uncoordinated_data = spring_model.draw_samples(num_series=1, num_time_steps=T_plot, coordination_samples=coordination, seed=SEED).observation.values[0]\n",
    "\n",
    "coordination = np.ones((1, T_plot)) * 2/3\n",
    "spring_coordinated_data = spring_model.draw_samples(num_series=1, num_time_steps=T_plot, coordination_samples=coordination, seed=SEED).observation.values[0]\n",
    "\n",
    "coordination = np.ones((1, T_plot))\n",
    "spring_supercoordinated_data = spring_model.draw_samples(num_series=1, num_time_steps=T_plot, coordination_samples=coordination, seed=SEED).observation.values[0]\n",
    "\n",
    "coordination = np.ones((1, T_plot)) * 0.2\n",
    "spring_0_2_data = spring_model.draw_samples(num_series=1, num_time_steps=T_plot, coordination_samples=coordination, seed=SEED).observation.values[0]\n",
    "\n",
    "coordination = np.ones((1, T_plot)) * 0.8\n",
    "spring_0_8_data = spring_model.draw_samples(num_series=1, num_time_steps=T_plot, coordination_samples=coordination, seed=SEED).observation.values[0]\n",
    "\n",
    "# Noisy version for inference\n",
    "spring_model.state_space_cpn.parameters.sd_aa.value=np.ones(1) * SD_AA_SPR\n",
    "spring_model.observation_cpn.parameters.sd_o.value=np.ones(1) * SD_O_SPR\n",
    "\n",
    "coordination = np.zeros((1, T))\n",
    "noisy_spring_uncoordinated_data = spring_model.draw_samples(num_series=1, num_time_steps=T, coordination_samples=coordination, seed=SEED).observation.values[0]\n",
    "\n",
    "coordination = np.ones((1, T)) * 2/3\n",
    "noisy_spring_coordinated_data = spring_model.draw_samples(num_series=1, num_time_steps=T, coordination_samples=coordination, seed=SEED).observation.values[0]\n",
    "\n",
    "coordination = np.ones((1, T))\n",
    "noisy_spring_supercoordinated_data = spring_model.draw_samples(num_series=1, num_time_steps=T, coordination_samples=coordination, seed=SEED).observation.values[0]\n",
    "\n",
    "coordination = np.ones((1, T)) * 0.2\n",
    "noisy_spring_0_2_data = spring_model.draw_samples(num_series=1, num_time_steps=T, coordination_samples=coordination, seed=SEED).observation.values[0]\n",
    "\n",
    "coordination = np.ones((1, T)) * 0.8\n",
    "noisy_spring_0_8_data = spring_model.draw_samples(num_series=1, num_time_steps=T, coordination_samples=coordination, seed=SEED).observation.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85e484d-0c8d-496d-87ac-a3292e61bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "w, h = calculate_best_figure_dimensions(document_width=DOC_WIDTH, scale=1, subplots=(2,3))  \n",
    "fig, axs = plt.subplots(2, 3, figsize=(w,h*1.5))\n",
    "axs[0,1].sharey(axs[0,0])\n",
    "axs[1,1].sharey(axs[1,0])\n",
    "\n",
    "v_pos = 15\n",
    "x_slice = [0, 30]\n",
    "\n",
    "plot_spring_data(axs[0,0], spring_uncoordinated_data, title=f\"C = 0\", y_shift_fn=lambda x, s: x + s*10)\n",
    "axs[0,0].plot([v_pos, v_pos], [-1, 25], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "axs[0,0].set_xlim(x_slice)\n",
    "plot_spring_data(axs[0,1], spring_0_2_data, title=f\"C = 0.2\", line_width=1, y_shift_fn=lambda x, s: x + s*10)\n",
    "axs[0,1].plot([v_pos, v_pos], [-1, 25], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "axs[0,1].set_xlim(x_slice)\n",
    "plot_spring_data(axs[0,2], spring_coordinated_data, title=f\"C = 2/3\", line_width=1, y_shift_fn=lambda x, s: x + s*10)\n",
    "axs[0,2].plot([v_pos, v_pos], [-1, 25], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "axs[0,2].set_xlim(x_slice)\n",
    "plot_spring_data(axs[1,0], spring_0_8_data, title=f\"C = 0.8\", line_width=1, y_shift_fn=lambda x, s: x + s*10)\n",
    "axs[1,0].plot([v_pos, v_pos], [-1, 25], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "axs[1,0].set_xlim(x_slice)\n",
    "plot_spring_data(axs[1,1], spring_supercoordinated_data, title=f\"C = 1\", line_width=1, y_shift_fn=lambda x, s: x + s*10)\n",
    "axs[1,1].plot([v_pos, v_pos], [-1, 25], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "axs[1,1].set_xlim(x_slice)\n",
    "\n",
    "axs[0,1].set_ylabel(\"\")\n",
    "axs[0,2].set_ylabel(\"\")\n",
    "axs[1,1].set_ylabel(\"\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a9e068-daa4-42a9-8648-a9ebc21584db",
   "metadata": {},
   "source": [
    "## b) Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2db15f-8fdd-4882-9988-a01f21d2c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for data generation\n",
    "conversation_model.state_space_cpn.parameters.mean_a0.value=INITIAL_STATE_CONV\n",
    "conversation_model.state_space_cpn.parameters.sd_aa.value=np.zeros(1)  # only for plots\n",
    "conversation_model.observation_cpn.parameters.sd_o.value=np.zeros(1)\n",
    "\n",
    "# Denoised version is only used for plots\n",
    "T_plot = 200\n",
    "fixed_subject_sequence = True\n",
    "\n",
    "coordination = np.zeros((1, T_plot))\n",
    "conversation_uncoordinated_data = conversation_samples_to_evidence(conversation_model.draw_samples(num_series=1, num_time_steps=T_plot, coordination_samples=coordination, seed=SEED, fixed_subject_sequence=fixed_subject_sequence))\n",
    "\n",
    "coordination = np.ones((1, T_plot)) * 0.5\n",
    "conversation_coordinated_data = conversation_samples_to_evidence(conversation_model.draw_samples(num_series=1, num_time_steps=T_plot, coordination_samples=coordination, seed=SEED, fixed_subject_sequence=fixed_subject_sequence))\n",
    "\n",
    "coordination = np.ones((1, T_plot))\n",
    "conversation_supercoordinated_data = conversation_samples_to_evidence(conversation_model.draw_samples(num_series=1, num_time_steps=T_plot, coordination_samples=coordination, seed=SEED, fixed_subject_sequence=fixed_subject_sequence))\n",
    "\n",
    "coordination = np.ones((1, T_plot)) * 0.2\n",
    "conversation_0_2_data = conversation_samples_to_evidence(conversation_model.draw_samples(num_series=1, num_time_steps=T_plot, coordination_samples=coordination, seed=SEED, fixed_subject_sequence=fixed_subject_sequence))\n",
    "\n",
    "coordination = np.ones((1, T_plot)) * 0.8\n",
    "conversation_0_8_data = conversation_samples_to_evidence(conversation_model.draw_samples(num_series=1, num_time_steps=T_plot, coordination_samples=coordination, seed=SEED, fixed_subject_sequence=fixed_subject_sequence))\n",
    "\n",
    "# Noisy version for inference\n",
    "conversation_model.state_space_cpn.parameters.sd_aa.value=np.ones(1) * SD_AA_CONV\n",
    "conversation_model.observation_cpn.parameters.sd_o.value=np.ones(1) * SD_O_CONV\n",
    "\n",
    "coordination = np.zeros((1, T))\n",
    "noisy_conversation_uncoordinated_data = conversation_samples_to_evidence(conversation_model.draw_samples(num_series=1, num_time_steps=T, coordination_samples=coordination, seed=SEED, fixed_subject_sequence=True))\n",
    "\n",
    "coordination = np.ones((1, T)) * 0.5\n",
    "noisy_conversation_coordinated_data = conversation_samples_to_evidence(conversation_model.draw_samples(num_series=1, num_time_steps=T, coordination_samples=coordination, seed=SEED, fixed_subject_sequence=True))\n",
    "\n",
    "coordination = np.ones((1, T))\n",
    "noisy_conversation_supercoordinated_data = conversation_samples_to_evidence(conversation_model.draw_samples(num_series=1, num_time_steps=T, coordination_samples=coordination, seed=SEED, fixed_subject_sequence=True))\n",
    "\n",
    "coordination = np.ones((1, T)) * 0.2\n",
    "noisy_conversation_0_2_data = conversation_samples_to_evidence(conversation_model.draw_samples(num_series=1, num_time_steps=T, coordination_samples=coordination, seed=SEED, fixed_subject_sequence=True))\n",
    "\n",
    "coordination = np.ones((1, T)) * 0.8\n",
    "noisy_conversation_0_8_data = conversation_samples_to_evidence(conversation_model.draw_samples(num_series=1, num_time_steps=T, coordination_samples=coordination, seed=SEED, fixed_subject_sequence=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9c751-db44-4502-a93d-c7b2477ec970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "w, h = calculate_best_figure_dimensions(document_width=DOC_WIDTH, scale=1, subplots=(2,3))  \n",
    "fig, axs = plt.subplots(2, 3, figsize=(w,h*1.5))\n",
    "axs[0,1].sharey(axs[0,0])\n",
    "# axs[1,1].sharey(axs[1,0])\n",
    "\n",
    "v_pos = 45\n",
    "x_slice = [0, 200]\n",
    "\n",
    "plot_conversation_data(axs[0,0], conversation_uncoordinated_data, title=f\"C = 0\", line_width=1, y_shift_fn=lambda x, s: x + s*2.5)\n",
    "axs[0,0].set_xlim(x_slice)\n",
    "axs[0,0].plot([v_pos, v_pos], [-1, 7], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "plot_conversation_data(axs[0,1], conversation_0_2_data, title=f\"C = 0.2\", line_width=1, y_shift_fn=lambda x, s: x + s*2.5)\n",
    "axs[0,1].set_xlim(x_slice)\n",
    "axs[0,1].plot([v_pos, v_pos], [-1, 7], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "plot_conversation_data(axs[0,2], conversation_coordinated_data, title=f\"C = 0.5\", line_width=1, y_shift_fn=lambda x, s: x + s*2.5)\n",
    "axs[0,2].set_xlim(x_slice)\n",
    "axs[0,2].plot([v_pos, v_pos], [-1, 7], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "plot_conversation_data(axs[1,0], conversation_0_8_data, title=f\"C = 0.8\", line_width=1, y_shift_fn=lambda x, s: x + s*2.5)\n",
    "axs[1,0].set_xlim(x_slice)\n",
    "axs[1,0].plot([v_pos, v_pos], [-1, 7], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "plot_conversation_data(axs[1,1], conversation_supercoordinated_data, title=f\"C = 1\", line_width=1, y_shift_fn=lambda x, s: x + s*2.5)\n",
    "axs[1,1].set_xlim(x_slice)\n",
    "axs[1,1].plot([v_pos, v_pos], [-1, 7], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "\n",
    "\n",
    "axs[0,1].set_ylabel(\"\")\n",
    "axs[0,2].set_ylabel(\"\")\n",
    "axs[1,1].set_ylabel(\"\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a73df1-f616-4f15-87f4-90196427b62d",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70735a65-2f1a-4a12-a75a-e78c38b35a31",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0d47f4-2e37-475a-a4a7-1d68fbf9512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: Any, \n",
    "          evidence: Any, \n",
    "          init_method: str = NUTS_INIT_METHOD,\n",
    "          burn_in: int = BURN_IN, \n",
    "          num_samples: int = NUM_SAMPLES, \n",
    "          num_chains: int = NUM_CHAINS, \n",
    "          target_accept: float = TARGET_ACCEPT,\n",
    "          seed : int = SEED):\n",
    "    \n",
    "    # Ignore PyMC warnings\n",
    "    if not sys.warnoptions:\n",
    "        import warnings\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    # The environment variables below will make sure each chain does not take all the resources, slowing down inference.\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = f\"{num_chains}\"\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = f\"{num_chains}\"\n",
    "    os.environ[\"OPENBLAS_NUM_THREADS\"] = f\"{num_chains}\"\n",
    "    \n",
    "    model.clear_parameter_values()  # so we can infer them\n",
    "    _, idata = model.fit(evidence=evidence, \n",
    "                         init_method=init_method,\n",
    "                         burn_in=burn_in, \n",
    "                         num_samples=num_samples, \n",
    "                         num_chains=num_chains,\n",
    "                         seed=seed, \n",
    "                         num_jobs=num_chains,\n",
    "                         target_accept=target_accept)\n",
    "    \n",
    "    posterior_samples = CoordinationPosteriorSamples.from_inference_data(idata)\n",
    "    \n",
    "    # Plot parameter trace\n",
    "    plot_parameter_trace(model, idata)\n",
    "\n",
    "    # Plot coordination\n",
    "    w, h = calculate_best_figure_dimensions(document_width=DOC_WIDTH, scale=1)  \n",
    "    fig = plt.figure(figsize=(w,h))\n",
    "    \n",
    "    posterior_samples.plot(fig.gca(), show_samples=False, line_width=1)\n",
    "    plt.title(\"Coordination\")\n",
    "    \n",
    "    return posterior_samples, idata\n",
    "\n",
    "def plot_parameter_trace(model: Any, idata: Any):\n",
    "    sampled_vars = set(idata.posterior.data_vars)\n",
    "    var_names = sorted(list(set(model.parameter_names).intersection(sampled_vars)))    \n",
    "    az.plot_trace(idata, var_names=var_names)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def build_convergence_summary(idata: Any) -> pd.DataFrame:\n",
    "    header = [\n",
    "        \"variable\",\n",
    "        \"mean_rhat\",\n",
    "        \"std_rhat\"\n",
    "    ]\n",
    "    \n",
    "    rhat = az.rhat(idata)\n",
    "    data = []\n",
    "    for var, values in rhat.data_vars.items():\n",
    "        entry = [\n",
    "            var,\n",
    "            values.to_numpy().mean(),\n",
    "            values.to_numpy().std()\n",
    "        ]\n",
    "        data.append(entry)\n",
    "\n",
    "    return pd.DataFrame(data, columns=header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d857c2d-06c3-41f2-87f3-a7d72337e4bc",
   "metadata": {},
   "source": [
    "## 1) No Coordination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d38a742-0637-43b7-92e8-88a302cdb437",
   "metadata": {},
   "source": [
    "### 1.1) Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d69efb-5b31-45dd-adad-9edb81aa7fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = noisy_spring_uncoordinated_data\n",
    "\n",
    "c_posterior_spring_uncoordinated, idata_spring_uncoordinated = train(spring_model, evidence)\n",
    "build_convergence_summary(idata_spring_uncoordinated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc50f85-1bb0-47bf-9a6d-b3ef218bde15",
   "metadata": {},
   "source": [
    "### 1.2) Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9bdafb-845f-4606-88b9-796703dedd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = noisy_conversation_uncoordinated_data\n",
    "\n",
    "c_posterior_conversation_uncoordinated, idata_conversation_uncoordinated = train(conversation_model, evidence)\n",
    "build_convergence_summary(idata_conversation_uncoordinated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be0081d-6e88-4f59-bac1-86f9cf95c95c",
   "metadata": {},
   "source": [
    "## 2) Maximum Coordination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af49f39-9aed-4437-b357-3c907d4e2e8e",
   "metadata": {},
   "source": [
    "### 2.1) Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9a7ed-22cc-4453-a048-a6a2ad80f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = noisy_spring_coordinated_data\n",
    "\n",
    "c_posterior_spring_coordinated, idata_spring_coordinated = train(spring_model, evidence)\n",
    "build_convergence_summary(idata_spring_coordinated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d03dee-6d03-4fa0-be3b-4f56f7de7ad9",
   "metadata": {},
   "source": [
    "### 2.2) Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd403a56-d2a1-43da-ba11-e9e96edd37ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = noisy_conversation_coordinated_data\n",
    "\n",
    "c_posterior_conversation_coordinated, idata_conversation_coordinated = train(conversation_model, evidence)\n",
    "build_convergence_summary(idata_conversation_coordinated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ec754-f6bb-42a9-81e2-5d63f15c8cd9",
   "metadata": {},
   "source": [
    "## 3) Supercoordination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e74122b-539c-493a-bf2d-97b20e9b2546",
   "metadata": {},
   "source": [
    "### 3.1) Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b63ff6-5188-4ff5-958a-d12b85c6313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = noisy_spring_supercoordinated_data\n",
    "\n",
    "c_posterior_spring_supercoordinated, idata_spring_supercoordinated = train(spring_model, evidence)\n",
    "build_convergence_summary(idata_spring_supercoordinated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba8039f-3bef-4c78-b81c-6f87400ba4d4",
   "metadata": {},
   "source": [
    "### 3.2) Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8a52c-20ad-4c3b-8a0d-127bfbcf725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = noisy_conversation_supercoordinated_data\n",
    "\n",
    "c_posterior_conversation_supercoordinated, idata_conversation_supercoordinated = train(conversation_model, evidence)\n",
    "build_convergence_summary(idata_conversation_supercoordinated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5789148-6fb6-4b05-80eb-ff5bd676d2e5",
   "metadata": {},
   "source": [
    "## 4) Coordination = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e17b6b1-9e10-44dd-8c62-0a9849182b9f",
   "metadata": {},
   "source": [
    "### 4.1) Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69170bfa-d1f0-4ec5-980d-d1e452912262",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = noisy_spring_0_2_data\n",
    "\n",
    "c_posterior_spring_0_2, idata_spring_0_2 = train(spring_model, evidence)\n",
    "build_convergence_summary(idata_spring_0_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ba10c-9111-4e48-9573-9e2967155027",
   "metadata": {},
   "source": [
    "### 4.2) Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0324f1f7-7bd7-448e-8275-78ef20119186",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = noisy_conversation_0_2_data\n",
    "\n",
    "c_posterior_conversation_0_2, idata_conversation_0_2 = train(conversation_model, evidence)\n",
    "build_convergence_summary(idata_conversation_0_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf8dfdb-c1af-4f63-b4f7-ef71b3da5ef1",
   "metadata": {},
   "source": [
    "## 5) Coordination = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49401a08-5d38-410c-bd66-3049a3f96908",
   "metadata": {},
   "source": [
    "### 5.1) Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c33613-9060-4e4b-bdfc-e1ec81b81ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = noisy_spring_0_8_data\n",
    "\n",
    "c_posterior_spring_0_8, idata_spring_0_8 = train(spring_model, evidence)\n",
    "build_convergence_summary(idata_spring_0_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f2fcfb-9253-48c6-80b5-d3c9b70e23a0",
   "metadata": {},
   "source": [
    "### 5.2) Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a8c8c-4f48-4efe-b417-ab9dc45ab1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = noisy_conversation_0_8_data\n",
    "\n",
    "c_posterior_conversation_0_8, idata_conversation_0_8 = train(conversation_model, evidence)\n",
    "build_convergence_summary(idata_conversation_0_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41135a41-c909-4643-8cfe-84c65463a0c1",
   "metadata": {},
   "source": [
    "# Final Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc980e9-bf37-4735-909b-b9f31a4c6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_formatter(x, pos):\n",
    "    result = x\n",
    "    if result == 0:\n",
    "        return '0'\n",
    "    # If not 0, format as multiples of 1000 (1K, 2K, 3K, etc.)\n",
    "    return f'{result/1000:.1f}K'\n",
    "\n",
    "def save_plot(image_name: str, fig: Any, format: str = \"pdf\"):\n",
    "    fig.savefig(f\"../assets/images/{image_name}.{format}\", format=format, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db151f83-d68d-42ff-8f52-d2d5b4596a25",
   "metadata": {},
   "source": [
    "## a) Spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe82bae-d731-4245-bbea-2fdd1b614536",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = calculate_best_figure_dimensions(document_width=DOC_WIDTH, scale=1, subplots=(2,3))  \n",
    "fig, axs = plt.subplots(2, 3, figsize=(w, h*1.5))\n",
    "\n",
    "v_pos = 15\n",
    "x_slice = [0, 20]\n",
    "\n",
    "axs[0,1].sharey(axs[0,0])\n",
    "axs[1,1].sharey(axs[1,0])\n",
    "\n",
    "# Data plots\n",
    "plot_spring_data(axs[0,0], spring_uncoordinated_data, line_width=1, y_shift_fn=lambda x, s: x + s*10)\n",
    "axs[0,0].set_ylabel(\"Spring Position\")\n",
    "axs[0,0].set_xlabel(\"Time Step\")\n",
    "axs[0,0].set_title(\"Data (c = 0)\")\n",
    "axs[0,0].set_xlim(x_slice)\n",
    "axs[0,0].plot([v_pos, v_pos], [-2, 25], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "\n",
    "plot_spring_data(axs[0,1], spring_0_2_data, line_width=1, y_shift_fn=lambda x, s: x + s*10)\n",
    "axs[0,1].set_ylabel(\"\")\n",
    "axs[0,1].set_xlabel(\"Time Step\")\n",
    "axs[0,1].set_title(\"Data (c = 0.2)\")\n",
    "axs[0,1].set_xlim(x_slice)\n",
    "axs[0,1].plot([v_pos, v_pos], [-2, 25], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "\n",
    "plot_spring_data(axs[0,2], spring_coordinated_data, line_width=1, y_shift_fn=lambda x, s: x + s*10)\n",
    "axs[0,2].set_ylabel(\"\")\n",
    "axs[0,2].set_xlabel(\"Time Step\")\n",
    "axs[0,2].set_title(\"Data (c = 2/3)\")\n",
    "axs[0,2].set_xlim(x_slice)\n",
    "axs[0,2].plot([v_pos, v_pos], [-2, 25], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "\n",
    "plot_spring_data(axs[1,0], spring_0_8_data, line_width=1, y_shift_fn=lambda x, s: x + s*10)\n",
    "axs[1,0].set_ylabel(\"Spring Position\")\n",
    "axs[1,0].set_xlabel(\"Time Step\")\n",
    "axs[1,0].set_title(\"Data (c = 0.8)\")\n",
    "axs[1,0].set_xlim(x_slice)\n",
    "axs[1,0].plot([v_pos, v_pos], [-2, 25], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "\n",
    "plot_spring_data(axs[1,1], spring_supercoordinated_data, line_width=1, y_shift_fn=lambda x, s: x + s*10)\n",
    "axs[1,1].set_ylabel(\"\")\n",
    "axs[1,1].set_xlabel(\"Time Step\")\n",
    "axs[1,1].set_title(\"Data (c = 1)\")\n",
    "axs[1,1].set_xlim(x_slice)\n",
    "axs[1,1].plot([v_pos, v_pos], [-2, 25], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "\n",
    "c_posterior_spring_uncoordinated.plot(axs[1,2], show_samples=False, line_width=0.5, color=\"tab:red\", label=\"c = 0\")\n",
    "c_posterior_spring_0_2.plot(axs[1,2], show_samples=False, line_width=0.5, color=\"tab:purple\", label=\"c = 0.2\")\n",
    "c_posterior_spring_coordinated.plot(axs[1,2], show_samples=False, line_width=0.5, color=MUSTARD, label=\"c = 2/3\")\n",
    "c_posterior_spring_0_8.plot(axs[1,2], show_samples=False, line_width=0.5, color=\"tab:green\", label=\"c = 0.8\")\n",
    "c_posterior_spring_supercoordinated.plot(axs[1,2], show_samples=False, line_width=0.5, color=\"tab:blue\", label=\"c = 1\")\n",
    "axs[1,2].set_title(\"Inferred Coordination\")\n",
    "axs[1,2].set_xlabel(\"\")\n",
    "axs[1,2].set_ylabel(\"Coordination\")\n",
    "axs[1,2].set_xlabel(\"Time Step\")\n",
    "sns.despine(ax=axs[1,2])\n",
    "\n",
    "handles, labels = axs[0,0].get_legend_handles_labels()\n",
    "leg = fig.legend(handles, labels, loc='upper right', ncol=1, bbox_to_anchor=[1.15, 0.9], frameon=True, markerscale=15, columnspacing=1.4, title=\"Spring\")\n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(1.5)\n",
    "\n",
    "handles, labels = axs[1,2].get_legend_handles_labels()\n",
    "leg = fig.legend(handles, labels, loc='lower right', ncol=1, bbox_to_anchor=[1.18, 0.13], frameon=True, markerscale=15, columnspacing=1.4, title=\"Coordination\")\n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_plot(\"results_spring_model\", fig, \"png\")\n",
    "save_plot(\"results_spring_model\", fig, \"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b2164b-6577-481b-84a6-03a7220ed05e",
   "metadata": {},
   "source": [
    "## b) Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e74372-51a5-4a3c-a87a-4f38daf89cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = calculate_best_figure_dimensions(document_width=DOC_WIDTH, scale=1, subplots=(2,3))  \n",
    "fig, axs = plt.subplots(2, 3, figsize=(w, h*1.5))\n",
    "\n",
    "v_pos = 45\n",
    "x_slice = [0, 200]\n",
    "\n",
    "axs[0,1].sharey(axs[0,0])\n",
    "axs[1,1].sharey(axs[1,0])\n",
    "\n",
    "# Data plots\n",
    "plot_conversation_data(axs[0,0], conversation_uncoordinated_data, y_shift_fn=lambda x, s: x + s*2.5)\n",
    "axs[0,0].set_ylabel(\"Voice Intensity\")\n",
    "axs[0,0].set_xlabel(\"Time Step\")\n",
    "axs[0,0].set_title(\"Data (c = 0)\")\n",
    "axs[0,0].plot([v_pos, v_pos], [-2, 6], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "axs[0,0].set_xlim(x_slice)\n",
    "\n",
    "plot_conversation_data(axs[0,1], conversation_0_2_data, y_shift_fn=lambda x, s: x + s*2.5)\n",
    "axs[0,1].set_ylabel(\"\")\n",
    "axs[0,1].set_xlabel(\"Time Step\")\n",
    "axs[0,1].set_title(\"Data (c = 0.2)\")\n",
    "axs[0,1].plot([v_pos, v_pos], [-2, 6], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "axs[0,1].set_xlim(x_slice)\n",
    "\n",
    "plot_conversation_data(axs[0,2], conversation_coordinated_data, y_shift_fn=lambda x, s: x + s*2.5)\n",
    "axs[0,2].set_ylabel(\"\")\n",
    "axs[0,2].set_xlabel(\"Time Step\")\n",
    "axs[0,2].set_title(\"Data (c = 0.5)\")\n",
    "axs[0,2].plot([v_pos, v_pos], [-2, 6], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "axs[0,2].set_xlim(x_slice)\n",
    "\n",
    "plot_conversation_data(axs[1,0], conversation_0_8_data, y_shift_fn=lambda x, s: x + s*2.5)\n",
    "axs[1,0].set_ylabel(\"Voice Intensity\")\n",
    "axs[1,0].set_xlabel(\"Time Step\")\n",
    "axs[1,0].set_title(\"Data (c = 0.8)\")\n",
    "axs[1,0].plot([v_pos, v_pos], [-2, 6], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "axs[1,0].set_xlim(x_slice)\n",
    "\n",
    "plot_conversation_data(axs[1,1], conversation_supercoordinated_data, y_shift_fn=lambda x, s: x + s*2.5)\n",
    "axs[1,1].set_ylabel(\"\")\n",
    "axs[1,1].set_xlabel(\"Time Step\")\n",
    "axs[1,1].set_title(\"Data (c = 1)\")\n",
    "axs[1,1].plot([v_pos, v_pos], [-2, 6], linestyle=\"dotted\", linewidth=0.7, color=\"black\")\n",
    "axs[1,1].set_xlim(x_slice)\n",
    "\n",
    "c_posterior_conversation_uncoordinated.plot(axs[1,2], show_samples=False, line_width=0.5, color=\"tab:red\", label=\"c = 0\")\n",
    "c_posterior_conversation_0_2.plot(axs[1,2], show_samples=False, line_width=0.5, color=\"tab:purple\", label=\"c = 0.2\")\n",
    "c_posterior_conversation_coordinated.plot(axs[1,2], show_samples=False, line_width=0.5, color=MUSTARD, label=\"c = 0.5\")\n",
    "c_posterior_conversation_0_8.plot(axs[1,2], show_samples=False, line_width=0.5, color=\"tab:green\", label=\"c = 0.8\")\n",
    "c_posterior_conversation_supercoordinated.plot(axs[1,2], show_samples=False, line_width=0.5, color=\"tab:blue\", label=\"c = 1\")\n",
    "axs[1,2].set_title(\"Inferred Coordination\")\n",
    "axs[1,2].set_xlabel(\"\")\n",
    "axs[1,2].set_ylabel(\"Coordination\")\n",
    "axs[1,2].set_xlabel(\"Time Step\")\n",
    "sns.despine(ax=axs[1,2])\n",
    "\n",
    "handles, labels = axs[0,0].get_legend_handles_labels()\n",
    "leg = fig.legend(handles, labels, loc='upper right', ncol=1, bbox_to_anchor=[1.15, 0.9], frameon=True, markerscale=15, columnspacing=1.4, title=\"Speaker\")\n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(1.5)\n",
    "\n",
    "handles, labels = axs[1,2].get_legend_handles_labels()\n",
    "leg = fig.legend(handles, labels, loc='lower right', ncol=1, bbox_to_anchor=[1.18, 0.13], frameon=True, markerscale=15, columnspacing=1.4, title=\"Coordination\")\n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.tight_layout()\n",
    "save_plot(\"results_conversation_model\", fig, \"png\")\n",
    "save_plot(\"results_conversation_model\", fig, \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ea604-f7b2-4db2-bd2f-6ce444f9cba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coordination_notebooks",
   "language": "python",
   "name": "coordination_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
